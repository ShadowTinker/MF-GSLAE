mlp_hidden_size: [200]          # (list of int) The MLP hidden layer.
latent_dimension: 64           # (int) The latent dimension of auto-encoder.
learning_rate: 1e-3
use_user_loader: true

dropout_prob: 0.5               # (float) The drop out probability of input.
nogb: false                     # (bool) Whether to disable Gumbel-Softmax sampling.
nobinarize: true
tau_gsl: 0.5
tau_source: 0.2                        # (float) Temperature of sigmoid/softmax, in (0,oo).
tau_target: 0.2                        # (float) Temperature of sigmoid/softmax, in (0,oo).
reg_weights: [0.0, 0.0]         # (list of float) L2 regularization weights.  
source_loss: 1
target_loss: 1
kfac: 16

graph_threshold: 0.9
gnn_layers: 3
graph_noise: 0.2
cl_weight: 0.

# ablation
no_mask: false
no_gsl: true

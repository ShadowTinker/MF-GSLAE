{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.6668 0.6664]]\n",
      "[-2.33306667]\n",
      "[[1. 1.]\n",
      " [2. 3.]\n",
      " [3. 2.]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "\n",
    "x = [[2,3], [3, 2], [1,1]]\n",
    "y = [1, 1, -1]\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(x, y)\n",
    "\n",
    "print(clf.coef_)\n",
    "print(clf.intercept_)\n",
    "print(clf.support_vectors_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mjyin/miniconda3/envs/recbole-cdr/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import dgl\n",
    "import scipy.sparse as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'[0, 1, 2]'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str([0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(14.9016, grad_fn=<NegBackward0>)\n"
     ]
    }
   ],
   "source": [
    "rating = F.relu(torch.randn(5, 10)).bool().float()\n",
    "encoder = nn.Linear(10, 2)\n",
    "cates = nn.Embedding(3, 2)\n",
    "decoder = nn.Linear(2, 10)\n",
    "cores = (F.normalize(decoder.weight) @ F.normalize(cates.weight).T).softmax(-1)\n",
    "\n",
    "from recbole_cdr.model.layers import Binarize\n",
    "\n",
    "binary = Binarize.apply\n",
    "\n",
    "rec_list = []\n",
    "for _ in range(cates.weight.shape[0]):\n",
    "    rating_k = rating * cores.T[_:_+1]\n",
    "    h = F.normalize(encoder(rating_k))\n",
    "    rec_list.append(decoder(h))\n",
    "rec = sum(rec_list)\n",
    "loss = -(F.log_softmax(rec, 1) * rating).sum(1).mean()\n",
    "print(loss)\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 2])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = F.relu(torch.randn(6, 6)).bool().float()\n",
    "cates = torch.randn(5, 6).softmax(0)\n",
    "graph_list = []\n",
    "for _ in range(5):\n",
    "    cate = cates[_:_+1]\n",
    "    graph = F.normalize(data * cate)\n",
    "    graph = graph @ graph.T\n",
    "    graph_list.append(graph)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.000, 0.642, 0.000, 0.000, 0.000, 0.360],\n",
       "        [0.642, 1.000, 0.000, 0.653, 0.354, 0.562],\n",
       "        [0.000, 0.000, 1.000, 0.169, 0.887, 0.827],\n",
       "        [0.000, 0.653, 0.169, 1.000, 0.543, 0.506],\n",
       "        [0.000, 0.354, 0.887, 0.543, 1.000, 0.933],\n",
       "        [0.360, 0.562, 0.827, 0.506, 0.933, 1.000]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.000, 0.857, 0.000, 0.000, 0.000, 0.377],\n",
       "        [0.857, 1.000, 0.000, 0.480, 0.126, 0.440],\n",
       "        [0.000, 0.000, 1.000, 0.036, 0.970, 0.898],\n",
       "        [0.000, 0.480, 0.036, 1.000, 0.263, 0.243],\n",
       "        [0.000, 0.126, 0.970, 0.263, 1.000, 0.926],\n",
       "        [0.377, 0.440, 0.898, 0.243, 0.926, 1.000]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_list[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[-1.973, -1.418, -1.368],\n",
      "         [-0.911, -0.895, -0.260],\n",
      "         [-1.073,  1.095, -0.585]],\n",
      "\n",
      "        [[-1.147,  0.992,  0.478],\n",
      "         [ 0.970,  0.976,  0.422],\n",
      "         [-0.661,  0.102, -0.968]]])\n",
      "tensor([-1.418, -1.368, -0.911, -0.260, -1.073,  1.095,  0.992,  0.478,  0.970,\n",
      "         0.422, -0.661,  0.102])\n"
     ]
    }
   ],
   "source": [
    "def off_diagonal(x):\n",
    "    b, n, m = x.shape\n",
    "    assert n == m\n",
    "    return x.flatten(-2, -1)[:, :-1].view(b, n - 1, n + 1)[:, :, 1:].flatten()\n",
    "data = torch.randn(2, 3, 3)\n",
    "print(data)\n",
    "print(off_diagonal(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.073,  1.089,  0.627,  0.943],\n",
       "        [ 0.607, -0.264,  1.133, -0.484]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.flatten()[:-1].view(2, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 1.000, -0.609,  0.171],\n",
       "         [-0.609,  1.000, -0.231],\n",
       "         [ 0.171, -0.231,  1.000]],\n",
       "\n",
       "        [[ 1.000,  0.631, -0.186],\n",
       "         [ 0.631,  1.000,  0.415],\n",
       "         [-0.186,  0.415,  1.000]],\n",
       "\n",
       "        [[ 1.000,  0.354, -0.209],\n",
       "         [ 0.354,  1.000, -0.523],\n",
       "         [-0.209, -0.523,  1.000]],\n",
       "\n",
       "        [[ 1.000,  0.050,  0.226],\n",
       "         [ 0.050,  1.000,  0.530],\n",
       "         [ 0.226,  0.530,  1.000]],\n",
       "\n",
       "        [[ 1.000, -0.230, -0.130],\n",
       "         [-0.230,  1.000,  0.131],\n",
       "         [-0.130,  0.131,  1.000]],\n",
       "\n",
       "        [[ 1.000,  0.405,  0.501],\n",
       "         [ 0.405,  1.000,  0.802],\n",
       "         [ 0.501,  0.802,  1.000]],\n",
       "\n",
       "        [[ 1.000,  0.540, -0.457],\n",
       "         [ 0.540,  1.000, -0.056],\n",
       "         [-0.457, -0.056,  1.000]],\n",
       "\n",
       "        [[ 1.000, -0.038,  0.850],\n",
       "         [-0.038,  1.000,  0.383],\n",
       "         [ 0.850,  0.383,  1.000]],\n",
       "\n",
       "        [[ 1.000,  0.503,  0.335],\n",
       "         [ 0.503,  1.000,  0.294],\n",
       "         [ 0.335,  0.294,  1.000]],\n",
       "\n",
       "        [[ 1.000,  0.486,  0.225],\n",
       "         [ 0.486,  1.000,  0.591],\n",
       "         [ 0.225,  0.591,  1.000]]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data @ data.transpose(1, 2))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-0.100, -1.000,  0.100,  1.000], requires_grad=True)\n",
      "tensor(18., grad_fn=<SumBackward0>)\n",
      "tensor([0., 0., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "from recbole_cdr.model.layers import Binarize\n",
    "binary = Binarize.apply\n",
    "emb = torch.cat([\n",
    "    torch.ones(2, 3, 3, requires_grad=True),\n",
    "    torch.ones(2, 3, 3, requires_grad=True),\n",
    "])\n",
    "mask = torch.tensor([-0.1, -1, 0.1, 1], requires_grad=True)\n",
    "print(mask)\n",
    "loss = F.relu((binary(mask).unsqueeze(1).unsqueeze(1) * emb)).sum()\n",
    "print(loss)\n",
    "loss.backward()\n",
    "print(mask.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mjyin/miniconda3/envs/recbole-cdr/lib/python3.9/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.000, -0.990, -0.313, -0.320, -0.384, -0.287, -0.228, -0.299, -0.266,\n",
      "         -0.268],\n",
      "        [-0.990,  1.000,  0.330,  0.366,  0.433,  0.327,  0.278,  0.344,  0.317,\n",
      "          0.315],\n",
      "        [-0.313,  0.330,  1.000,  0.921,  0.792,  0.746,  0.698,  0.632,  0.585,\n",
      "          0.534],\n",
      "        [-0.320,  0.366,  0.921,  1.000,  0.904,  0.839,  0.806,  0.758,  0.723,\n",
      "          0.665],\n",
      "        [-0.384,  0.433,  0.792,  0.904,  1.000,  0.926,  0.886,  0.845,  0.815,\n",
      "          0.759],\n",
      "        [-0.287,  0.327,  0.746,  0.839,  0.926,  1.000,  0.965,  0.911,  0.878,\n",
      "          0.817],\n",
      "        [-0.228,  0.278,  0.698,  0.806,  0.886,  0.965,  1.000,  0.953,  0.916,\n",
      "          0.866],\n",
      "        [-0.299,  0.344,  0.632,  0.758,  0.845,  0.911,  0.953,  1.000,  0.961,\n",
      "          0.921],\n",
      "        [-0.266,  0.317,  0.585,  0.723,  0.815,  0.878,  0.916,  0.961,  1.000,\n",
      "          0.961],\n",
      "        [-0.268,  0.315,  0.534,  0.665,  0.759,  0.817,  0.866,  0.921,  0.961,\n",
      "          1.000]])\n",
      "tensor([[     0.006,      5.954,      0.001,      6.920,     -1.029,      6.360,\n",
      "             -6.757,      6.912,     -5.489,     -6.923]])\n",
      "tensor([[    -0.183,      0.003,      0.008,      0.004,      0.004,     -5.487,\n",
      "              6.290,     -4.741,      4.515,      4.966]])\n",
      "tensor([[1., 1., 1., 1., 0., 1., 0., 1., 0., 0.]])\n",
      "tensor([[0., 1., 1., 1., 1., 0., 1., 0., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from recbole_cdr.model.layers import Binarize\n",
    "binary = Binarize.apply\n",
    "\n",
    "path = 'recbole-cdr-ckpt/MacridDAE36-Aug-03-2023_10-25-21.313869.pth'\n",
    "file = torch.load(path, map_location='cpu')\n",
    "para = file['state_dict']\n",
    "torch.set_printoptions(precision=3,sci_mode=False)\n",
    "L = para['cores_logvar.weight']\n",
    "L = torch.tril(L)\n",
    "L = F.normalize(L)\n",
    "print(L @ L.T)\n",
    "print(para['mask_source.weight'])\n",
    "print(para['mask_target.weight'])\n",
    "print(binary(para['mask_source.weight']))\n",
    "print(binary(para['mask_target.weight']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([     0.018+0.j,      0.011+0.j,      0.004+0.j,      0.002+0.j,      0.001+0.j,\n",
       "             0.001+0.j,      0.000+0.j,      0.000+0.j,     -0.000+0.j,      0.000+0.j])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linalg.eigvals(L @ L.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4472, 0.4472, 0.4472, 0.4472, 0.4472],\n",
       "        [0.4472, 0.4472, 0.4472, 0.4472, 0.4472],\n",
       "        [0.4472, 0.4472, 0.4472, 0.4472, 0.4472],\n",
       "        [0.4472, 0.4472, 0.4472, 0.4472, 0.4472],\n",
       "        [0.4472, 0.4472, 0.4472, 0.4472, 0.4472]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.normalize(torch.ones(5, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4556, 0.0780, 0.0832, 0.0215, 0.0351, 0.0583, 0.0557, 0.0616, 0.0282,\n",
       "         0.0680],\n",
       "        [0.0780, 0.4302, 0.0407, 0.0546, 0.1015, 0.0581, 0.0413, 0.0711, 0.0675,\n",
       "         0.0573],\n",
       "        [0.0832, 0.0407, 0.4533, 0.0374, 0.0638, 0.0650, 0.0538, 0.0776, 0.0198,\n",
       "         0.0235],\n",
       "        [0.0215, 0.0546, 0.0374, 0.4524, 0.0711, 0.0576, 0.0436, 0.0835, 0.0370,\n",
       "         0.0423],\n",
       "        [0.0351, 0.1015, 0.0638, 0.0711, 0.4420, 0.0649, 0.0255, 0.0500, 0.0497,\n",
       "         0.0616],\n",
       "        [0.0583, 0.0581, 0.0650, 0.0576, 0.0649, 0.4673, 0.0432, 0.0685, 0.0474,\n",
       "         0.0514],\n",
       "        [0.0557, 0.0413, 0.0538, 0.0436, 0.0255, 0.0432, 0.4598, 0.0493, 0.0757,\n",
       "         0.0599],\n",
       "        [0.0616, 0.0711, 0.0776, 0.0835, 0.0500, 0.0685, 0.0493, 0.4121, 0.0802,\n",
       "         0.0642],\n",
       "        [0.0282, 0.0675, 0.0198, 0.0370, 0.0497, 0.0474, 0.0757, 0.0802, 0.4713,\n",
       "         0.0540],\n",
       "        [0.0680, 0.0573, 0.0235, 0.0423, 0.0616, 0.0514, 0.0599, 0.0642, 0.0540,\n",
       "         0.4601]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "para['intent_graph']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = F.normalize(para['k_embedding.weight'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.0000, -0.2061,  0.1017, -0.0519, -0.1014,  0.1964, -0.0731,  0.0071,\n",
       "          0.0332, -0.2584],\n",
       "        [-0.2061,  1.0000, -0.1510, -0.0365,  0.0621, -0.3583,  0.0017,  0.0953,\n",
       "          0.0277,  0.1007],\n",
       "        [ 0.1017, -0.1510,  1.0000, -0.0960,  0.1342,  0.0763,  0.0417,  0.0913,\n",
       "         -0.1019,  0.0535],\n",
       "        [-0.0519, -0.0365, -0.0960,  1.0000, -0.0736,  0.1676,  0.2307, -0.1100,\n",
       "          0.0150, -0.0579],\n",
       "        [-0.1014,  0.0621,  0.1342, -0.0736,  1.0000,  0.1688, -0.0911,  0.0505,\n",
       "         -0.0730,  0.1633],\n",
       "        [ 0.1964, -0.3583,  0.0763,  0.1676,  0.1688,  1.0000,  0.0529,  0.0302,\n",
       "         -0.0715,  0.1613],\n",
       "        [-0.0731,  0.0017,  0.0417,  0.2307, -0.0911,  0.0529,  1.0000,  0.0203,\n",
       "         -0.1387,  0.0125],\n",
       "        [ 0.0071,  0.0953,  0.0913, -0.1100,  0.0505,  0.0302,  0.0203,  1.0000,\n",
       "          0.2779,  0.0314],\n",
       "        [ 0.0332,  0.0277, -0.1019,  0.0150, -0.0730, -0.0715, -0.1387,  0.2779,\n",
       "          1.0000, -0.2568],\n",
       "        [-0.2584,  0.1007,  0.0535, -0.0579,  0.1633,  0.1613,  0.0125,  0.0314,\n",
       "         -0.2568,  1.0000]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cores @ cores.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = para['mask_source.weight']\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = para['mask_target.weight']\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_source = (para['mask_source.weight'] > 0)\n",
    "mask_source"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_target = (para['mask_target.weight'] > 0)\n",
    "mask_target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(~(mask_source | mask_target)).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = F.normalize(para['item_embedding.weight'], dim=1)\n",
    "cores = F.normalize(para['k_embedding.weight'], dim=1)\n",
    "cates_logits = torch.matmul(items, cores.transpose(0, 1)) / 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val, idx = F.softmax(cates_logits, dim=-1).max(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randn(1, 5, requires_grad=True)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F.gumbel_softmax(data, hard=False, tau=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from recbole_cdr.model.layers import Binarize\n",
    "binary = Binarize.apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1 = nn.Embedding(1, 4)\n",
    "mask2 = nn.Embedding(1, 4)\n",
    "mask1.weight.data.copy_(torch.tensor([0.2, 0.5, 0.7, -0.5]))\n",
    "mask2.weight.data.copy_(torch.tensor([-0.4, 0.2, 0.6, -0.3]))\n",
    "net = nn.ModuleList([mask1, mask2])\n",
    "from torch.optim import Adam\n",
    "opt = Adam(net.parameters(), lr=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_mask1, b_mask2 = binary(mask1.weight), binary(mask2.weight)\n",
    "loss = (F.relu(1 - (b_mask1 + b_mask2))).sum()\n",
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.zero_grad()\n",
    "loss.backward()\n",
    "opt.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask2.weight"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "recbole-cdr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
